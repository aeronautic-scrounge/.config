# Orchestrate and Implement Commands: System Improvements Implementation Plan

## Metadata
- **Date**: 2025-10-12
- **Revision**: 1 (2025-10-12)
- **Feature**: /orchestrate and /implement command improvements
- **Scope**: Performance, reliability, developer experience, and maintainability enhancements
- **Estimated Phases**: 5 major phases (including new Phase 0)
- **Structure Level**: 1 (Phase expansion)
- **Expanded Phases**: [2]
- **Standards File**: /home/benjamin/.config/CLAUDE.md
- **Research Reports**:
  - /home/benjamin/.config/.claude/specs/reports/043_orchestrate_implement_improvement_opportunities.md
  - /home/benjamin/.config/.claude/specs/reports/044_plan_043_revision_recommendations.md
- **Complexity**: Medium-High (reduced from High via existing utility integration)
- **Priority**: High (40-60% performance gains, major reliability and UX improvements)

## Revision History

### 2025-10-12 - Revision 1
**Changes**: Complete overhaul to leverage existing .claude/lib/ utilities
**Reason**: Analysis revealed 67% redundancy with existing infrastructure
**Reports Used**: 044_plan_043_revision_recommendations.md
**Modified Phases**: All phases restructured; added Phase 0 for foundation integration
**Key Changes**:
- Added Phase 0: Foundation Integration (prerequisite)
- Phase 1: Changed from "create retry-with-backoff" to "integrate error-utils.sh"
- Phase 2: Changed from "create parallel-executor" to "use parse-phase-dependencies.sh + inline logic"
- Phase 3: Changed from "add recovery functions" to "integrate existing recovery + create dashboard"
- Phase 4: Changed from "create agent-invocation" to "integrate agent-registry-utils.sh"
- Reduced duration: 13-17 sessions → 9-11 sessions (35% reduction)
- Reduced new utilities: 6 → 2 (progress-dashboard.sh, workflow-metrics.sh)

## Overview

This plan implements critical improvements to the /orchestrate and /implement commands by **leveraging existing mature utilities** in .claude/lib/ and adding genuinely new functionality. Analysis revealed that 4 of 6 originally proposed utilities already exist with battle-tested implementations.

**Key Strategy Shift**: Integration over recreation

**Improvements Delivered**:
- **40-60% performance gains** through parallel phase execution
- **Significantly improved reliability** via existing retry-with-backoff from error-utils.sh
- **Professional user experience** with new progress dashboard and existing error recovery
- **Maintainable codebase** through utility integration and focused refactoring

**Existing Infrastructure Leveraged**:
- error-utils.sh (700+ lines): retry_with_backoff, error classification, recovery strategies
- parse-phase-dependencies.sh: wave generation for parallel execution
- checkpoint-utils.sh: robust checkpoint management with schema migration
- complexity-utils.sh: comprehensive complexity analysis
- adaptive-planning-logger.sh: structured logging infrastructure
- agent-registry-utils.sh: agent metrics tracking and performance analysis

## Success Criteria

### Performance
- [ ] Parallel phase execution reduces implementation time by 40-60% for plans with independent phases
- [ ] Agent failure rate reduced from ~15% to <5% via retry_with_backoff integration
- [ ] Test failure resolution time reduced by 30% via existing error recovery

### Reliability
- [ ] Commands source and use shared utilities consistently
- [ ] Retry logic uses battle-tested error-utils.sh implementation
- [ ] Test failure recovery uses existing detect_error_type() and generate_suggestions()

### User Experience
- [ ] New progress dashboard provides real-time visibility into workflow status
- [ ] Error messages use existing format_error_report() for consistency
- [ ] New dry-run mode allows validation before execution

### Code Quality
- [ ] Commands properly source all shared utilities
- [ ] Phase execution logic modularized into phase-executor.sh
- [ ] All existing utilities actively integrated (not just documented)
- [ ] Unit test coverage ≥70% for new utilities only

## Technical Design

### Architecture Overview

Revised architecture focuses on integration rather than duplication:

```
┌─────────────────────────────────────────────────────┐
│ Commands Layer                                       │
│  ├─ /implement (uses shared utilities)             │
│  └─ /orchestrate (uses shared utilities)            │
└─────────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────────┐
│ New Utilities (2 genuinely new)                     │
│  ├─ progress-dashboard.sh (ANSI rendering - NEW)   │
│  └─ workflow-metrics.sh (analytics aggregation)     │
└─────────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────────┐
│ Refactored Utilities (extraction)                   │
│  └─ phase-executor.sh (extracted from /implement)   │
└─────────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────────┐
│ Existing Utilities (mature, battle-tested)          │
│  ├─ error-utils.sh (retry, classify, recover)      │
│  ├─ parse-phase-dependencies.sh (wave generation)   │
│  ├─ checkpoint-utils.sh (state management)          │
│  ├─ complexity-utils.sh (complexity scoring)        │
│  ├─ adaptive-planning-logger.sh (logging)           │
│  └─ agent-registry-utils.sh (agent metrics)         │
└─────────────────────────────────────────────────────┘
```

### Key Design Decisions

**1. Integration First, Creation Second**
- Source all existing utilities before implementing phases
- Replace inline logic with shared utility functions
- Only create utilities that genuinely don't exist

**2. Leverage Existing Complexity Analysis**
- Use complexity-utils.sh (already comprehensive)
- No need for agent-based complexity (complexity-utils.sh sufficient)
- Reuse calculate_phase_complexity() and analyze_feature_description()

**3. Wave-Based Parallel Execution with parse-phase-dependencies.sh**
- Reuse existing wave generation (already implemented)
- Add inline parallel invocation logic (simple, doesn't justify separate utility)
- Max 3 concurrent phases per wave

**4. Tiered Error Recovery Using error-utils.sh**
- Level 1: detect_error_type() + generate_suggestions() (already exist)
- Level 2: retry_with_timeout() (already exists)
- Level 3: retry_with_fallback() (already exists)
- Level 4: Debug agent invocation

**5. Incremental Rollout**
- New features behind flags (--dashboard, --dry-run)
- Graceful fallbacks (ANSI dashboard → PROGRESS markers)
- Backward compatibility maintained

## Implementation Phases

### Phase 0: Foundation Integration (NEW - PREREQUISITE)
**Objective**: Integrate existing utilities into commands before adding new features
**Complexity**: Low-Medium
**Duration**: 1-2 sessions
**Priority**: Critical (prerequisite for all other phases)

**Rationale**: Commands currently document utility usage but don't actually source them. This phase establishes the foundation for all subsequent improvements.

Tasks:
- [ ] Add utility sourcing to /implement command
  - Source detect-project-dir.sh
  - Source error-utils.sh
  - Source checkpoint-utils.sh
  - Source complexity-utils.sh
  - Source adaptive-planning-logger.sh
  - Source agent-registry-utils.sh
- [ ] Add utility sourcing to /orchestrate command
  - Source same utilities as /implement
  - Add sourcing at command initialization
- [ ] Replace inline retry logic with retry_with_backoff()
  - Find inline retry implementations in commands
  - Replace with retry_with_backoff calls
  - Update parameters to match existing function signature
- [ ] Replace inline error handling with error-utils.sh functions
  - Use classify_error() instead of inline classification
  - Use suggest_recovery() for recovery options
  - Use format_error_report() for structured output
- [ ] Replace inline checkpoint logic with checkpoint-utils.sh functions
  - Use save_checkpoint() instead of manual JSON
  - Use restore_checkpoint() for resumption
  - Use validate_checkpoint() before loading
- [ ] Replace inline logging with adaptive-planning-logger.sh functions
  - Use log_trigger_evaluation() for adaptive triggers
  - Use log_complexity_check() for complexity evaluations
  - Use log_replan_invocation() for replanning
- [ ] Test integration with existing workflows
  - Run /implement on test plan
  - Run /orchestrate on simple workflow
  - Verify utilities sourced correctly
- [ ] Verify no regressions in command behavior
  - Compare before/after behavior
  - Check that all tests still pass
  - Validate log output format

Testing:
```bash
# Verify utilities are sourced correctly
/implement test_plan.md  # Should use shared utilities
/orchestrate "simple feature"  # Should use shared retry logic

# Check logs for utility function calls
grep "retry_with_backoff" .claude/logs/adaptive-planning.log
grep "classify_error" .claude/logs/adaptive-planning.log
grep "save_checkpoint" .claude/logs/adaptive-planning.log

# Verify no regressions
.claude/tests/test_command_integration.sh
```

**Expected Impact**: Foundation for all subsequent phases, eliminates redundancy, ensures consistency

---

### Phase 1: Error Recovery Integration (revised)
**Objective**: Integrate existing error-utils.sh for reliable error handling
**Complexity**: Low-Medium (reduced from Medium via existing utilities)
**Duration**: 1-2 sessions (reduced from 2-3)
**Effort Reduction**: 40% (no new utility creation, only integration)

**What Changed**: Instead of creating retry-with-backoff.sh, integrate existing error-utils.sh (700+ lines of battle-tested code)

Tasks:
- [ ] Integrate error-utils.sh into /orchestrate command
  - Wrap agent invocations with retry_with_backoff
  - Use classify_error() to categorize agent failures
  - Use suggest_recovery() to provide recovery options
  - Add retry logging via adaptive-planning-logger.sh
- [ ] Enhance error-utils.sh with /orchestrate-specific error contexts
  - Add orchestrate_agent_failure() error template
  - Include workflow phase context in error messages
  - Show agent type and invocation parameters
  - Provide resume commands using checkpoint paths
- [ ] Update /implement command to use error-utils.sh
  - Replace generic "Agent failed" with format_error_report()
  - Use detect_error_type() for test failure classification
  - Use generate_suggestions() for actionable troubleshooting
  - Display recovery options via suggest_recovery()
- [ ] Test error recovery with simulated failures
  - Verify retry_with_backoff works with Task tool invocations
  - Test exponential backoff timing (2s base, exponential increase)
  - Ensure logging output includes retry attempts
  - Validate recovery suggestions are relevant

Testing:
```bash
# Test retry integration
.claude/tests/test_retry_integration.sh

# Test error classification
.claude/tests/test_error_classification.sh

# Integration test with simulated failures
/implement test_plan.md  # Should show improved error UX with recovery options

# Verify error-utils.sh functions used
grep "retry_with_backoff" .claude/logs/adaptive-planning.log
grep "classify_error" .claude/logs/adaptive-planning.log
```

**Expected Impact**: Agent failures reduced by 50%, consistent error handling, battle-tested retry logic

---

### Phase 2: Parallel Phase Execution (Medium-High)
**Objective**: Enable 40-60% performance improvement using existing parse-phase-dependencies.sh
**Status**: PENDING
**Complexity**: 7/10 (High architectural complexity)

**Summary**: Transforms /implement from sequential to wave-based parallel execution. Introduces fundamental architectural changes including wave coordination, concurrent agent invocation, checkpoint schema extensions, and sophisticated result aggregation. This phase achieves 40-60% performance gains by executing independent phases concurrently while maintaining fail-fast error handling.

**Key Architecture Changes**:
- Wave-based execution model with state machine (11 states)
- Multiple Task tool invocations in single message for parallelism
- Extended checkpoint schema tracking wave state and results
- Inline result aggregation from parallel agents
- Race condition detection and mitigation

For detailed implementation specification, see [Phase 2 Details](phase_2_parallel_phase_execution.md)

---

### Phase 3: Dashboard & Error Recovery Integration (revised)
**Objective**: Create new progress dashboard and integrate existing error recovery
**Complexity**: Medium
**Duration**: 2-3 sessions (reduced from 3-4)
**Effort Reduction**: 35% (reuse extensive error recovery from error-utils.sh)

**What Changed**: Focus on creating genuinely new progress-dashboard.sh. Integrate existing recovery functions instead of creating new ones.

Tasks:
- [ ] Integrate existing error-utils.sh recovery into /implement
  - Use detect_error_type() to classify test failures (syntax, import, null, timeout, etc.)
  - Use generate_suggestions() for auto-recovery hints (context-aware)
  - Use handle_partial_failure() for partial wave completion
  - Log recovery attempts via adaptive-planning-logger.sh
- [ ] Add tiered recovery logic to /implement
  - Level 1: Use suggestions from generate_suggestions() (syntax, imports)
  - Level 2: Use retry_with_timeout() for transient failures (already exists)
  - Level 3: Use retry_with_fallback() for tool access errors (already exists)
  - Level 4: Escalate to debug agent for complex failures
- [ ] Create `.claude/lib/progress-dashboard.sh` utility (NEW - genuinely new functionality)
  - Implement render_dashboard() function
  - Use ANSI escape codes for in-place updates
  - Calculate progress percentage (completed/total phases)
  - Estimate remaining time using historical metrics
  - Display phase list with status icons (✓ completed, → in progress, pending)
  - Show current task and test results
  - Include wave information for parallel execution
- [ ] Add dashboard support to /implement command
  - Add --dashboard flag (default: traditional output)
  - Detect terminal capabilities (check for ANSI support)
  - Fallback to PROGRESS markers if unsupported
  - Update dashboard after each phase completion
  - Clear dashboard on completion or error
- [ ] Test recovery integration and dashboard
  - Verify detect_error_type() and generate_suggestions() integration
  - Test tiered recovery attempts with simulated failures
  - Test dashboard rendering in various terminals (bash, zsh, tmux)
  - Verify fallback to PROGRESS markers on unsupported terminals

Testing:
```bash
# Test error recovery integration
.claude/tests/test_recovery_integration.sh

# Test progress dashboard (new)
.claude/tests/test_progress_dashboard.sh

# Integration test with dashboard
/implement test_plan.md --dashboard
# Should display real-time dashboard with phase progress

# Test terminal compatibility
TERM=dumb /implement test_plan.md --dashboard
# Should fallback to PROGRESS markers

# Verify recovery functions used
grep "detect_error_type" .claude/logs/adaptive-planning.log
grep "generate_suggestions" .claude/logs/adaptive-planning.log
```

**Expected Impact**: Professional UX via new dashboard, 30% faster test failure resolution via existing recovery

---

### Phase 4: Refactoring & New Features (revised)
**Objective**: Extract phase-executor.sh, add dry-run mode, integrate agent registry
**Complexity**: Medium
**Duration**: 4-5 sessions (reduced from 6-8)
**Effort Reduction**: 45% (reuse agent-registry-utils.sh, complexity-utils.sh, checkpoint-utils.sh)

**What Changed**: Focus on valuable extraction (phase-executor.sh) and genuinely new features (dry-run, metrics aggregation). Integrate existing agent-registry-utils.sh instead of creating new system.

Tasks:
- [ ] Extract phase execution module from /implement
  - Create `.claude/lib/phase-executor.sh` utility
  - Extract execute_phase() function (phase orchestration)
  - Extract run_phase_tests() function (test execution)
  - Extract handle_test_failure() function (uses error-utils.sh)
  - Extract commit_phase_changes() function (git commits)
  - Extract update_plan_status() function (mark complete)
  - Update /implement to delegate to phase-executor.sh
- [ ] Integrate agent-registry-utils.sh into /orchestrate and /implement
  - Source agent-registry-utils.sh at command start
  - Call update_agent_metrics() after each Task tool invocation
  - Check get_agent_info() before invocation for success rate warnings
  - Use existing registry instead of creating new tracking system
  - Display agent performance summary at workflow completion
- [ ] Simplify research report handling in /orchestrate
  - After research phase, pass report content (not paths) to planning agent
  - Limit content size (5000 lines max per report)
  - Use simple string concatenation (no complex caching infrastructure)
  - Clear content after workflow completes
- [ ] Add dry-run mode to /implement and /orchestrate (NEW - genuinely new)
  - Add --dry-run flag to both commands
  - Parse plan and display execution plan without running
  - Show agent assignments based on complexity (use complexity-utils.sh)
  - Estimate duration using agent-registry-utils.sh historical metrics
  - List files/tests affected via plan analysis
  - Prompt for confirmation before actual execution
  - Support --dry-run with --dashboard for preview
- [ ] Create workflow metrics aggregation utility (NEW - analytics layer)
  - Create `.claude/lib/workflow-metrics.sh` utility
  - Aggregate data from adaptive-planning.log and agent-registry.json
  - Calculate workflow-level metrics (total time, phase breakdown)
  - Calculate agent-level metrics (invocations, success rate, avg duration)
  - Generate performance reports (markdown format)
  - Display summary after workflow completion
  - Add `/analyze workflow` command for historical analysis
- [ ] Test infrastructure components
  - Unit tests for phase-executor.sh extraction
  - Unit tests for workflow-metrics.sh aggregation
  - Integration tests for dry-run mode
  - Integration tests for agent-registry-utils.sh usage
  - Verify metrics accuracy against actual runs

Testing:
```bash
# Test phase executor extraction
.claude/tests/test_phase_executor.sh

# Test agent registry integration
.claude/tests/test_agent_registry_integration.sh

# Test dry-run mode (new)
/implement test_plan.md --dry-run
# Should display execution plan without running, show estimated duration

/orchestrate "Add feature X" --dry-run
# Should show research topics, planning approach, estimated time

# Test workflow metrics (new)
/implement test_plan.md
# Should display performance summary at end with phase times, agent stats

# Test metrics aggregation
.claude/tests/test_workflow_metrics.sh

# Verify agent registry updates
cat .claude/agents/agent-registry.json | jq '.agents["code-writer"]'
# Should show updated metrics after runs
```

**Expected Impact**: Maintainable codebase via extraction, valuable dry-run UX, integrated agent tracking, actionable metrics

---

## Testing Strategy

### Unit Tests
Comprehensive unit tests for new and extracted utilities:

```bash
.claude/tests/
  ├─ test_retry_integration.sh (error-utils.sh integration)
  ├─ test_parallel_waves.sh (parse-phase-dependencies.sh usage)
  ├─ test_parallel_agents.sh (parallel invocation pattern)
  ├─ test_recovery_integration.sh (error recovery integration)
  ├─ test_progress_dashboard.sh (NEW - dashboard rendering)
  ├─ test_phase_executor.sh (extracted phase execution)
  ├─ test_agent_registry_integration.sh (registry usage)
  ├─ test_workflow_metrics.sh (NEW - metrics aggregation)
  └─ run_all_tests.sh (test runner)
```

### Integration Tests
Test commands end-to-end with various scenarios:

```bash
.claude/tests/integration/
  ├─ test_implement_parallel.sh (parallel execution with waves)
  ├─ test_implement_recovery.sh (tiered failure recovery)
  ├─ test_implement_dashboard.sh (NEW - dashboard display)
  ├─ test_orchestrate_integration.sh (utility integration)
  ├─ test_dry_run.sh (NEW - dry-run mode)
  └─ test_utility_sourcing.sh (verify all utilities sourced)
```

### Test Coverage Goals
- Unit test coverage: ≥70% for new utilities (progress-dashboard.sh, workflow-metrics.sh)
- Integration test coverage: All major workflows with utility integration
- Regression test coverage: Verify no behavior changes from utility integration

## Documentation Requirements

### Updated Command Documentation
- [ ] /implement command: Add --dashboard, --dry-run flags; document utility integration
- [ ] /orchestrate command: Add --dry-run flag; document utility integration
- [ ] Update "Shared Utilities Integration" sections to reflect actual usage
- [ ] Add examples showing utility function calls
- [ ] Document wave-based execution with parse-phase-dependencies.sh

### New Utility Documentation
- [ ] progress-dashboard.sh: Usage, ANSI codes, terminal compatibility, fallback behavior
- [ ] workflow-metrics.sh: Metrics tracked, aggregation logic, report format
- [ ] phase-executor.sh: Extracted functions, integration with /implement

### Utility Integration Documentation
- [ ] Document error-utils.sh integration pattern
- [ ] Document parse-phase-dependencies.sh wave generation usage
- [ ] Document agent-registry-utils.sh metrics tracking integration
- [ ] Document checkpoint-utils.sh proper sourcing and usage

### Architecture Documentation
- [ ] Update command-patterns.md: utility integration pattern
- [ ] Document wave-based parallel execution using existing utilities
- [ ] Document tiered error recovery using error-utils.sh
- [ ] Document dry-run mode architecture

## Dependencies

### Required Tools
- bash ≥4.0 (for associative arrays)
- jq (for JSON parsing)
- git (for version control)
- grep, sed, awk (for text processing)

### Optional Tools
- bats (for enhanced unit testing)
- tput (for terminal capability detection in dashboard)

### Existing Utilities (leveraged)
- error-utils.sh (retry, error classification, recovery strategies)
- parse-phase-dependencies.sh (wave generation)
- checkpoint-utils.sh (state management with schema migration)
- complexity-utils.sh (complexity analysis and scoring)
- adaptive-planning-logger.sh (structured logging)
- agent-registry-utils.sh (agent metrics tracking)

### New Utilities (created)
- progress-dashboard.sh (ANSI terminal rendering)
- workflow-metrics.sh (analytics aggregation)
- phase-executor.sh (extracted from /implement)

## Risk Mitigation

### High-Risk: Utility Integration Breaking Changes
**Risk**: Sourcing utilities could break existing inline logic

**Mitigation**:
- Phase 0 dedicated to integration with comprehensive testing
- Verify no regressions before proceeding to other phases
- Maintain backups of original command implementations
- Gradual replacement of inline logic (one function at a time)
- Extensive integration testing

### Medium-Risk: Parallel Phase Execution
**Risk**: Race conditions, result aggregation bugs

**Mitigation**:
- Leverage mature parse-phase-dependencies.sh (already battle-tested)
- Inline aggregation logic kept simple (no complex parallel-executor.sh)
- Comprehensive logging of parallel operations
- --sequential flag to disable parallelization
- Fail-fast behavior limits blast radius

### Medium-Risk: Progress Dashboard Terminal Compatibility
**Risk**: ANSI handling breaks on different terminals

**Mitigation**:
- Detect terminal capabilities before using ANSI
- Graceful fallback to traditional PROGRESS markers
- Test on common terminals (bash, zsh, fish, tmux, screen)
- Dashboard opt-in via --dashboard flag
- Document known terminal limitations

### Low-Risk: Effort Estimation
**Risk**: Integration might take longer than anticipated

**Mitigation**:
- Utilities already exist and are well-documented
- Integration pattern is straightforward (source + replace)
- Phase 0 provides early validation of integration approach
- Each phase can proceed independently if needed

## Performance Targets

### Phase Execution Time
- **Baseline** (sequential): 5-phase plan = 15 minutes
- **Target** (parallel with parse-phase-dependencies.sh): 5-phase plan = 9 minutes (40% reduction)
- **Best case** (optimal parallelization): 6 minutes (60% reduction)

### Agent Failure Rate
- **Baseline**: ~15% agent invocation failures
- **Target**: <5% failures via retry_with_backoff integration (67% reduction)

### Test Failure Resolution Time
- **Baseline**: 5 minutes average (includes debug agent invocation)
- **Target**: 3.5 minutes average (30% reduction via existing error recovery)

### User Experience Metrics
- **Time to understand workflow**: 40% reduction with new progress dashboard
- **Successful first-time runs**: 70% → 90% (with dry-run validation)
- **Error message quality**: Consistent via error-utils.sh integration

## Success Validation

### Phase 0 Validation (Critical)
- [ ] All utilities sourced correctly in both commands
- [ ] No regressions in existing functionality
- [ ] Inline logic successfully replaced with utility functions
- [ ] Integration tests pass

### Phase 1 Validation
- [ ] retry_with_backoff successfully integrated
- [ ] Error classification uses classify_error()
- [ ] Recovery suggestions use suggest_recovery()
- [ ] Agent failures reduced by 50%

### Phase 2 Validation
- [ ] parse-phase-dependencies.sh successfully integrated
- [ ] Parallel execution reduces time by 40-60%
- [ ] Wave state tracked in checkpoints
- [ ] No race conditions in parallel phases

### Phase 3 Validation
- [ ] Progress dashboard renders correctly on supported terminals
- [ ] Fallback to PROGRESS markers works on unsupported terminals
- [ ] Error recovery uses existing error-utils.sh functions
- [ ] Test failure resolution time reduced by 30%

### Phase 4 Validation
- [ ] phase-executor.sh extraction successful
- [ ] agent-registry-utils.sh successfully integrated
- [ ] Dry-run mode provides accurate estimates
- [ ] Workflow metrics aggregation accurate

## Rollout Plan

### Stage 1: Foundation (Phase 0)
- Integrate existing utilities into commands
- Test extensively for regressions
- Validate integration approach
- **Gate**: All integration tests must pass before proceeding

### Stage 2: Core Improvements (Phases 1-2)
- Add error recovery integration
- Add parallel execution
- Gather performance metrics
- Refine based on testing

### Stage 3: UX Enhancements (Phase 3)
- Add progress dashboard
- Enable --dashboard flag
- Collect user feedback
- Fix terminal compatibility issues

### Stage 4: Infrastructure (Phase 4)
- Extract phase executor
- Add dry-run mode
- Add metrics aggregation
- Update documentation

### Stage 5: Optimization
- Analyze performance metrics via workflow-metrics.sh
- Tune thresholds based on data
- Address edge cases
- Continuous improvement

## Notes

### Implementation Order Rationale
1. **Foundation First** (Phase 0): Critical prerequisite, ensures utilities actually used
2. **Error Recovery Next** (Phase 1): Immediate reliability improvement via proven code
3. **Parallel Execution** (Phase 2): High impact, leverages existing wave generation
4. **UX Improvements** (Phase 3): New dashboard + existing recovery integration
5. **Infrastructure Last** (Phase 4): Extraction, dry-run, and metrics for maintainability

### Key Insights from Revision
- **67% redundancy eliminated**: 4 of 6 proposed utilities already exist
- **35% effort reduction**: 9-11 sessions vs 13-17 sessions
- **Quality improvement**: Battle-tested utilities vs new implementations
- **Consistency gains**: Single source of truth for error handling, retry, metrics

### Existing Utilities Are Comprehensive
- error-utils.sh: 700+ lines with comprehensive error handling
- checkpoint-utils.sh: Schema migration, parallel operation support
- complexity-utils.sh: Feature description pre-analysis, multi-level scoring
- agent-registry-utils.sh: Atomic updates, performance tracking
- All utilities have proper exports and are designed for sourcing

### Future Enhancements
After this plan completes, consider:
- Workflow visualization using metrics data (Low-medium priority)
- Integration tests for commands (High value for quality)
- Additional dashboard layouts (Low priority, after gathering feedback)
- Metrics dashboard web UI (Low priority, CLI first)

### Related Work
This plan builds on:
- Comprehensive utility analysis (report 044)
- Existing adaptive planning infrastructure
- Existing checkpoint system with replan tracking
- Existing agent system with registry
- parse-phase-dependencies.sh (mature wave generation)
- error-utils.sh (mature error handling)

### Maintenance Considerations
- Monitor agent-registry.json for agent performance trends
- Review adaptive-planning.log for common error patterns
- Update error-utils.sh recovery strategies based on failures
- Improve dashboard based on terminal compatibility feedback
- Continuously refine workflow-metrics.sh aggregation logic
